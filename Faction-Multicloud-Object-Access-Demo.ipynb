{"cells":[{"cell_type":"markdown","source":["This example notebook shows extremely simple access to Faction Object Multi-Cloud Data Service from Databricks, utilizing Spark configuration variable to supply credentials for access.\n\nCopyright 2022 Faction Group, LLC, under the terms of the MIT license https://opensource.org/licenses/MIT"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f6750124-5d35-424c-b540-3c676ea4780b"}}},{"cell_type":"code","source":["\n#NOTE: The assumed bucketname in this code is \"dbtest\"\n\nimport os, sys\nfrom operator import add\nfrom pyspark.sql import SparkSession\n\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"028ff4ef-6f56-405c-9bcb-21df5bf3ae6e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# You can configure your Faction MCDS-Object credentials and endpoint in the databricks spark configuration. Here is an example;\n# NOTE these must be replaced with *your URL*, access key, and secret key\n#\n# spark.hadoop.fs.s3a.bucket.dbtest.endpoint https://us-west-1.s3.faction.cloud\n# spark.hadoop.fs.s3a.bucket.dbtest.access.key XXXXXXXXXXXXXX\n# spark.hadoop.fs.s3a.bucket.dbtest.secret.key XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n\nsc._jsc.hadoopConfiguration().get(\"fs.s3a.bucket.dbtest.access.key\")\nsc._jsc.hadoopConfiguration().get(\"fs.s3a.bucket.dbtest.secret.key\")\nsc._jsc.hadoopConfiguration().get(\"fs.s3a.bucket.dbtest.endpoint\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e746b52f-4c02-4b18-94da-d3be3533abce"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# showing an unmount operation if desired\n\nif any(mount.mountPoint == \"/mnt/fctn\" for mount in dbutils.fs.mounts()):\n    dbutils.fs.unmount(\"/mnt/fctn\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0021d3d1-d4c3-404a-a361-e0bab2b106e9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# should work with string-based params, but if you have set the spark environment variables it is not needed\n# (eg, the sc._jsc.hadoopConfiguration().get(\"fs.s3a.bucket.dbtest.access.key\") entries are populated)\n#dbutils.fs.mount(\"s3a://%s:%s@dbtest\" % (ACCESS_KEY, SECRET_KEY), \"/mnt/fctn\")\ndbutils.fs.mount(\"s3a://dbtest\", \"/mnt/fctn\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d3b4b5d8-8e75-4bf5-b4b3-fac89d60ff6c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["x = dbutils.fs.mounts()\nfor y in x:\n    print(y)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"229a0cbe-b477-4c43-85e0-728b913fea53"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#print our Faction endpoint\n\nprint(sc._jsc.hadoopConfiguration().get(\"fs.s3a.bucket.dbtest.endpoint\"))\ndbutils.fs.ls(\"/\")\ndbutils.fs.ls(\"/mnt\")\n\n# note that databricks does not save credentials mapped to paths, so although you can mount the Faction MCDS-Object\n# you must still address it using the s3a:// path\nprint(dbutils.fs.ls(\"s3a://dbtest\"))\nprint(dbutils.fs.head(\"s3a://dbtest/cognito.py\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"535620cd-4572-4ca0-93f8-223a23206148"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["m = dbutils.fs.mounts()\nprint(m)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5ed2f2a8-e026-44b7-aaa3-7ee245da8b31"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"obj-test-new","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":4134835557766237}},"nbformat":4,"nbformat_minor":0}
